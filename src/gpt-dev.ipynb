{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import os\n",
    "\n",
    "# Download URL, the shakespeare.txt\n",
    "url = f'https://drive.google.com/uc?id=1O4PZ8wOpp6yecoy8tMuVEIFS7XgyRJy9'\n",
    "\n",
    "data_path = '../data'\n",
    "text_path = f'{data_path}/shakespeare.txt'\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)\n",
    "\n",
    "if not os.path.exists(text_path):\n",
    "  gdown.download(url, text_path, quiet=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenth of the text 5433453\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "with open(text_path) as f:\n",
    "  text = f.read()\n",
    "  \n",
    "text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "print(f\"lenth of the text {len(text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But as the riper should by time decease,\n",
      "  His tender heir might bear his memory:\n",
      "  But thou contracted to thine own bright eyes,\n",
      "  Feed'st thy light's flame with self-substantial fuel,\n",
      "  Making a famine where abundance lies,\n",
      "  Thy self thy foe, to thy sweet self too cruel:\n",
      "  Thou that art now the world's fresh ornament,\n",
      "  And only herald to the gaudy spring,\n",
      "  Within thine own bud buriest thy content,\n",
      "  And tender churl mak'st waste in niggarding:\n",
      "    Pity the world, or else this glutton be,\n",
      "    To eat the world's due, by the grave and thee.\n",
      "\n",
      "\n",
      "                     \n",
      "  When forty winters shall besiege thy brow,\n",
      "  And dig deep trenches in thy beauty's field,\n",
      "  Thy youth's proud livery so gazed on now,\n",
      "  Will be a tattered weed of small worth held:\n",
      "  Then being asked, where all thy beauty lies,\n",
      "  Where all the treasure of thy lusty days;\n",
      "  To say within thine own deep sunken eyes,\n",
      "  Were an all-ea\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size : 74\n",
      "\n",
      " !\"&'(),-.:;<>?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_`abcdefghijklmnopqrstuvwxyz|}\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(f\"vocab size : {len(chars)}\")\n",
    "print(\"\".join(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tiktoken\n",
    "# tokenizer = tiktoken.get_encoding('gpt2')\n",
    "# tokens = tokenizer.encode(text)\n",
    "# print(f\"total tokens {len(tokens)}\")\n",
    "# print(\"decode result of \\\"hello world.\\\"\", tokenizer.decode([31373, 995]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizer:\n",
    "  def __init__(self, text):\n",
    "    self.chars = sorted(list(set(text)))\n",
    "    self.token2id = {c : i for i, c in enumerate(chars)}\n",
    "    self.id2token = {i : c for i, c in enumerate(chars)}\n",
    "    \n",
    "  def encode(self, text):\n",
    "    return [self.token2id[c] for c in text]\n",
    "  \n",
    "  def decode(self, token_ids):\n",
    "    return \"\".join([self.id2token[token_id] for token_id in token_ids])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23, 50, 57, 57, 60]\n",
      "Hello\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizer(text)\n",
    "vocab_size = len(tokenizer.chars)\n",
    "print(\n",
    "  tokenizer.encode(\"Hello\"),\n",
    "  tokenizer.decode([23, 50, 57, 57, 60]),\n",
    "  sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data for torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  1, 21,  ..., 29, 19,  0]) torch.Size([5433453]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.tensor(tokenizer.encode(text), dtype = torch.long) # torch.long can be used as index directly\n",
    "print(data, data.shape, data.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_size = int(data.shape[0] * 0.9)\n",
    "train_data = data[:train_data_size].detach()\n",
    "val_data = data[train_data_size:].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class SimpleDataset(Dataset):\n",
    "  def __init__(self, data, block_size = 8):\n",
    "    self.data = data\n",
    "    self.block_size = block_size\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.data) - self.block_size\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    x = self.data[idx: idx + self.block_size]\n",
    "    y = self.data[idx + self.block_size]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SimpleDataset(train_data)\n",
    "val_dataset = SimpleDataset(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4890099 543338\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset), len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  1, 21, 63, 60, 58,  1, 51, 46])"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1,  1, 21, 63, 60, 58,  1, 51]), tensor(46))"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class SimpleDataloader(DataLoader):\n",
    "  def __init__(self, dataset, batch_size=4, shuffle=True, **kwargs):\n",
    "    super().__init__(dataset, batch_size=batch_size, shuffle=shuffle, **kwargs)\n",
    "    self.shuffle = shuffle\n",
    "  def __iter__(self):\n",
    "    dataset_size = len(self.dataset)\n",
    "    indices = np.arange(dataset_size)\n",
    "    if self.shuffle:\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "    for start_idx in range(0, dataset_size - self.batch_size + 1, self.batch_size):\n",
    "        batch_indices = indices[start_idx:start_idx + self.batch_size]\n",
    "        yield (torch.stack([self.dataset[i][0] for i in batch_indices]),\n",
    "              torch.stack([self.dataset[i][1] for i in batch_indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "train_dataloader = SimpleDataloader(train_dataset)\n",
    "val_dataloader = SimpleDataloader(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[70, 60, 66, 63,  1, 60, 68, 59],\n",
      "        [59, 49,  1, 53, 50, 63, 50,  8],\n",
      "        [54, 57, 60, 64, 60, 61, 53, 50],\n",
      "        [60, 51,  1, 53, 50, 46, 67, 50]]), tensor([12,  1, 63, 59]))\n",
      "(tensor([[ 1,  1,  1,  1,  1,  1,  1,  1],\n",
      "        [47, 66, 65,  1, 46, 59,  1, 46],\n",
      "        [63, 49,  8,  1, 54, 64,  1, 67],\n",
      "        [53, 50, 54, 63,  1, 47, 50, 64]]), tensor([ 1, 57, 46, 65]))\n",
      "(tensor([[ 1,  5, 65, 54, 64,  1, 58, 60],\n",
      "        [ 1, 16, 64,  1, 58, 66, 48, 53],\n",
      "        [12,  1, 46, 59, 49,  1, 65, 53],\n",
      "        [50, 63, 70, 10,  0,  1,  1,  1]]), tensor([64,  1, 60,  1]))\n",
      "(tensor([[64,  1, 68, 54, 57, 57,  1, 46],\n",
      "        [65, 53, 50,  1, 59, 60, 47, 57],\n",
      "        [57, 46, 65, 50, 64, 65,  1, 61],\n",
      "        [59, 54, 59, 52, 64,  8,  1, 64]]), tensor([59, 50, 46, 54]))\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_dataloader):\n",
    "  print(batch)\n",
    "  if i == 3:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Configuration\n",
    "VOCAB_SIZE = 74 # Should be set according to the tokenizer\n",
    "EMBED_DIM = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleGPT(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    # (B, T)\n",
    "    self.embedding = nn.Embedding(VOCAB_SIZE, VOCAB_SIZE) #(B, T, T)\n",
    "    \n",
    "\n",
    "  def forward(self, x):\n",
    "    \"\"\"\n",
    "    x should be in the form of (B, T)\n",
    "    The out out is (B, Vocab_size), indicating the probability\n",
    "    \"\"\"\n",
    "    y = self.embedding(x)\n",
    "    y = y[:, -1,:]\n",
    "    y = F.softmax(y, 1)\n",
    "    return y\n",
    "  \n",
    "  def generate(self, x, max_tokens = 30):\n",
    "    \"\"\"\n",
    "    x (B, T)\n",
    "\n",
    "    ### returns\n",
    "    y (B, T + max_tokens)\n",
    "\n",
    "    ### Warning\n",
    "    Because we do not have an EOF, so it will generate max_tokens actually\n",
    "    \"\"\"\n",
    "    for _ in range(max_tokens):\n",
    "      # x shape (B, T)\n",
    "      y = self.forward(x) # y shape (B, vocab_size)\n",
    "\n",
    "      \n",
    "      next_idx = torch.multinomial(y, 1)  # next_idx shape(B, 1)\n",
    "      x = torch.cat([x, next_idx], dim = 1)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = SimpleGPT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xz|\n",
      "ns\n",
      "W>-OHO[KO}}AiGFgfF eb>Z\n"
     ]
    }
   ],
   "source": [
    "input = torch.zeros(1, 1, dtype=torch.long)\n",
    "output = gpt.generate(input)\n",
    "print(tokenizer.decode(output[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
