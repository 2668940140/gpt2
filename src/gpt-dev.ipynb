{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import os\n",
    "\n",
    "# Download URL, the shakespeare.txt\n",
    "url = f'https://drive.google.com/uc?id=1O4PZ8wOpp6yecoy8tMuVEIFS7XgyRJy9'\n",
    "\n",
    "data_path = '../data'\n",
    "text_path = f'{data_path}/shakespeare.txt'\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)\n",
    "\n",
    "if not os.path.exists(text_path):\n",
    "  gdown.download(url, text_path, quiet=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenth of the text 5046489\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "with open(text_path) as f:\n",
    "  text = f.read()\n",
    "  \n",
    "text = re.sub(r'\\d+', '', text)\n",
    "text = re.sub(r' +', ' ', text)\n",
    "\n",
    "print(f\"lenth of the text {len(text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " From fairest creatures we desire increase,\n",
      " That thereby beauty's rose might never die,\n",
      " But as the riper should by time decease,\n",
      " His tender heir might bear his memory:\n",
      " But thou contracted to thine own bright eyes,\n",
      " Feed'st thy light's flame with self-substantial fuel,\n",
      " Making a famine where abundance lies,\n",
      " Thy self thy foe, to thy sweet self too cruel:\n",
      " Thou that art now the world's fresh ornament,\n",
      " And only herald to the gaudy spring,\n",
      " Within thine own bud buriest thy content,\n",
      " And tender churl mak'st waste in niggarding:\n",
      " Pity the world, or else this glutton be,\n",
      " To eat the world's due, by the grave and thee.\n",
      "\n",
      "\n",
      " \n",
      " When forty winters shall besiege thy brow,\n",
      " And dig deep trenches in thy beauty's field,\n",
      " Thy youth's proud livery so gazed on now,\n",
      " Will be a tattered weed of small worth held:\n",
      " Then being asked, where all thy beauty lies,\n",
      " Where all the treasure of thy lusty days;\n",
      " To say within thine own deep sunken eyes,\n",
      " Were an all-eating shame, and thriftless praise.\n",
      " How much m\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size : 74\n",
      "\n",
      " !\"&'(),-.:;<>?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_`abcdefghijklmnopqrstuvwxyz|}\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(f\"vocab size : {len(chars)}\")\n",
    "print(\"\".join(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tiktoken\n",
    "# tokenizer = tiktoken.get_encoding('gpt2')\n",
    "# tokens = tokenizer.encode(text)\n",
    "# print(f\"total tokens {len(tokens)}\")\n",
    "# print(\"decode result of \\\"hello world.\\\"\", tokenizer.decode([31373, 995]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizer:\n",
    "  def __init__(self, text):\n",
    "    self.chars = sorted(list(set(text)))\n",
    "    self.token2id = {c : i for i, c in enumerate(chars)}\n",
    "    self.id2token = {i : c for i, c in enumerate(chars)}\n",
    "    \n",
    "  def encode(self, text):\n",
    "    return [self.token2id[c] for c in text]\n",
    "  \n",
    "  def decode(self, token_ids):\n",
    "    return \"\".join([self.id2token[token_id] for token_id in token_ids])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23, 50, 57, 57, 60]\n",
      "Hello\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizer(text)\n",
    "vocab_size = len(tokenizer.chars)\n",
    "print(\n",
    "  tokenizer.encode(\"Hello\"),\n",
    "  tokenizer.decode([23, 50, 57, 57, 60]),\n",
    "  sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data for torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1, 21, 63,  ..., 29, 19,  0], device='cuda:0') torch.Size([5046489]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.tensor(tokenizer.encode(text), dtype = torch.long,\n",
    "                    device=device) # torch.long can be used as index directly\n",
    "print(data, data.shape, data.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_size = int(data.shape[0] * 0.9)\n",
    "train_data = data[:train_data_size].detach()\n",
    "val_data = data[train_data_size:].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class SimpleDataset(Dataset):\n",
    "  def __init__(self, data, block_size = 8):\n",
    "    self.data = data\n",
    "    self.block_size = block_size\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.data) - self.block_size\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    x = self.data[idx: idx + self.block_size]\n",
    "    y = self.data[idx + self.block_size]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "BLOCK_SIZE = 8\n",
    "train_dataset = SimpleDataset(train_data, BLOCK_SIZE)\n",
    "val_dataset = SimpleDataset(val_data, BLOCK_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4541832 504641\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset), len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 21, 63, 60, 58,  1, 51, 46, 54], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1, 21, 63, 60, 58,  1, 51, 46], device='cuda:0'),\n",
       " tensor(54, device='cuda:0'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class SimpleDataloader(DataLoader):\n",
    "  def __init__(self, dataset, batch_size=4, shuffle=True, **kwargs):\n",
    "    super().__init__(dataset, batch_size=batch_size, shuffle=shuffle, **kwargs)\n",
    "    self.shuffle = shuffle\n",
    "    \n",
    "  def __iter__(self):\n",
    "    dataset_size = len(self.dataset)\n",
    "    indices = np.arange(dataset_size)\n",
    "    if self.shuffle:\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "    for start_idx in range(0, dataset_size - self.batch_size + 1, self.batch_size):\n",
    "        batch_indices = indices[start_idx:start_idx + self.batch_size]\n",
    "        yield (torch.stack([self.dataset[i][0] for i in batch_indices]).to(device),\n",
    "              torch.stack([self.dataset[i][1] for i in batch_indices]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(0)\n",
    "train_dataloader = SimpleDataloader(train_dataset, BATCH_SIZE)\n",
    "val_dataloader = SimpleDataloader(val_dataset, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[49, 63, 60,  ..., 10,  1, 35],\n",
      "        [65, 68, 54,  ...,  1, 58, 70],\n",
      "        [31, 33, 30,  ..., 17, 24, 35],\n",
      "        ...,\n",
      "        [ 1, 47, 63,  ..., 52,  1, 53],\n",
      "        [24,  1, 58,  ..., 50, 57, 51],\n",
      "        [ 0,  1, 20,  ..., 65,  1, 38]], device='cuda:0'), tensor([53,  1, 20, 65, 66,  1, 66, 62, 53, 64, 51,  1, 59,  1,  1, 10,  1, 70,\n",
      "        33, 64, 50, 10, 57, 57, 55, 27,  1,  1, 50, 61, 63,  1, 50, 68, 46, 17,\n",
      "         0, 46, 46,  1, 68, 65, 66, 53, 70, 49, 20, 35, 50, 59,  0, 53, 50, 30,\n",
      "        60, 63, 10, 68,  1,  8, 53, 70, 64, 58,  1,  1, 66, 38, 59, 24, 35, 70,\n",
      "        65, 30, 52, 65, 60, 59, 58, 49, 65,  1, 54, 63, 27, 35, 57,  1,  1, 64,\n",
      "        53, 58, 34, 34,  1, 59, 46,  5, 54,  1, 59, 50, 65, 54, 56, 50, 54,  1,\n",
      "         1, 50,  5, 26,  0, 50, 57,  1, 34,  5,  1, 53, 64, 54, 64,  1, 46, 50,\n",
      "         1, 35, 30, 63,  5,  1, 65, 56,  1,  1,  1, 18,  1, 38, 46, 50,  1, 15,\n",
      "         1,  1,  1, 38, 58, 18, 60,  1, 49, 27,  1,  1, 46, 64, 50, 50,  1, 49,\n",
      "         1, 18,  1,  5, 58, 59, 59,  1, 59, 63, 52,  1, 65, 53, 52, 59, 64, 59,\n",
      "         1, 50, 46, 54, 50,  1, 60, 50, 46, 46, 30, 49,  1,  1, 12, 24,  1,  0,\n",
      "         1,  1, 48,  1, 46, 57, 23, 54, 66,  1,  0, 64, 58, 46, 68, 50, 50,  1,\n",
      "        46, 68, 63, 10, 10,  1, 64, 50, 48, 64,  1, 58,  1, 16,  1, 50, 60, 58,\n",
      "        54, 49,  1, 65,  0, 59, 50,  1,  1,  1, 61, 60, 46,  1, 53, 47, 59, 58,\n",
      "        67, 46, 53,  1, 65, 64,  1, 68, 50, 60, 60, 49, 60, 46, 53, 64,  1, 50,\n",
      "        63,  1, 49, 49,  1, 54, 67, 66, 59, 64, 67, 46,  1, 68, 53, 33, 53, 16,\n",
      "         0, 46, 59, 49,  1, 46,  1, 53, 50, 70, 68, 59, 59, 57, 50,  8, 33, 60,\n",
      "        53, 30, 65, 64, 59, 64, 64, 59,  8,  0, 10, 53, 54,  8,  8, 50, 60,  8,\n",
      "         1, 54,  1, 58,  5, 47, 49, 23, 58,  1, 10, 66, 53, 50,  1,  0,  1, 64,\n",
      "        61,  1, 46, 60, 48, 57,  1,  1,  0,  1, 28, 46, 65, 46, 64,  1, 47,  1,\n",
      "        64, 49, 70, 54,  1,  1, 60, 50, 64, 37, 58,  1, 60,  1, 65, 59, 50, 63,\n",
      "         1, 53, 59, 60, 57, 19, 48, 60, 51, 66,  0, 70, 51, 20, 65,  8,  1,  8,\n",
      "         0, 57, 63, 48, 63, 50, 49, 50, 61, 46, 70, 21, 48, 68, 64, 57, 46, 10,\n",
      "         1,  3, 54,  1, 16, 54, 53, 36, 65, 50, 17, 65, 54, 64, 58,  1, 18, 68,\n",
      "         1, 50, 64, 57, 50, 33,  1, 49, 29, 51, 46, 19, 65, 36, 49,  1,  1, 70,\n",
      "        63, 60, 38, 46, 53,  1,  1, 69, 54, 60,  8, 54, 65, 60, 68, 36, 54, 59,\n",
      "        67, 50,  1, 54,  1, 54,  1, 50, 33, 63, 65, 59, 56,  1, 28,  1,  1, 57,\n",
      "        65, 47, 59, 46, 51, 54, 35, 63,  1, 64,  1, 63, 66, 64, 60, 64,  1, 27,\n",
      "         1, 50, 50, 50, 49, 54,  0, 24], device='cuda:0'))\n",
      "(tensor([[57, 10,  1,  ..., 50, 46, 49],\n",
      "        [59, 60, 68,  ..., 60, 66,  1],\n",
      "        [29, 34, 10,  ..., 60, 58, 50],\n",
      "        ...,\n",
      "        [46, 59, 70,  ..., 57, 57,  8],\n",
      "        [38, 53, 50,  ...,  1, 65, 53],\n",
      "        [50,  1, 65,  ..., 46, 59, 65]], device='cuda:0'), tensor([64, 61,  8, 65, 65, 64, 19, 53, 54, 65, 52, 53, 65, 33, 63, 65,  1, 54,\n",
      "        51, 10, 50, 51, 46, 24, 64, 65, 56, 64, 10, 46, 58, 54, 34, 66, 66, 50,\n",
      "        53,  1, 70, 54, 53, 46, 63, 36, 30, 54,  1, 29, 19,  1,  1, 34,  1, 48,\n",
      "        65, 60,  1, 49, 48,  1, 63, 63, 48,  1, 60,  1, 59, 51,  1, 63, 65,  1,\n",
      "         1,  1, 59, 65,  0, 53, 33, 46, 50, 60, 66, 65,  1, 53,  1, 59, 66, 53,\n",
      "        53, 35, 63,  1, 35, 59,  1, 59,  1,  1,  1, 59, 46,  1, 49,  0, 30,  1,\n",
      "         1, 50, 28, 63,  1,  1, 49, 58, 64, 53, 51,  1, 59,  1,  1, 46, 63, 50,\n",
      "         8,  1,  1,  1, 54,  1, 64, 49, 57,  1, 21,  1, 63, 49, 53,  1, 22, 10,\n",
      "        53, 66,  1, 59, 61, 30,  1,  1, 64, 49, 70,  0, 65, 61, 51,  1,  1, 61,\n",
      "        60,  1, 63, 53, 65, 68, 34, 57, 46, 64,  1, 53, 48, 70, 65, 19,  1, 46,\n",
      "         1, 54, 60,  1, 52, 18,  1, 57,  1, 10, 53, 46, 46, 23, 54,  5, 59,  1,\n",
      "        57, 16, 64, 64, 65, 54, 51, 33, 20, 65, 66, 46, 16,  5, 46, 61,  1, 56,\n",
      "        17, 46, 58, 48, 50,  1, 54, 65, 65, 65, 64, 60, 54, 60, 57,  0, 46,  1,\n",
      "        50, 49, 46, 54, 31, 18, 65, 68, 60,  0,  1, 65, 49, 60, 65, 63, 63, 50,\n",
      "        21,  1, 60, 53, 57, 59, 50,  1, 50, 60, 65, 49, 33, 47, 53, 61,  1,  1,\n",
      "        66,  1, 53, 64, 54,  1,  1, 28, 59, 66, 33, 63, 15, 56, 57, 57, 49, 46,\n",
      "        54, 70, 59, 54, 51,  1, 54, 64, 52, 59, 65, 53,  1,  1,  8, 50, 53, 52,\n",
      "         1, 58,  1, 29, 23, 64, 61, 65, 65, 65, 12, 67, 63, 46, 50, 60,  1, 65,\n",
      "        34,  8, 63, 54, 10,  1, 10, 65, 60, 54,  1, 54,  1, 57, 64, 58, 60, 46,\n",
      "        49,  8, 60, 65, 12, 24, 59, 60, 64, 54,  0, 64,  1, 35, 57, 54, 58, 46,\n",
      "        10, 57, 68, 46, 60, 63, 64, 17,  1,  1, 70, 66, 50, 29, 60, 60,  1, 63,\n",
      "         1,  1, 36, 50,  1, 59,  5, 54, 50, 12, 60,  0,  1, 46, 49, 66, 47, 70,\n",
      "        60, 36, 66, 57, 53, 52, 58, 60, 60, 50, 59, 64, 70, 70, 50, 24, 65, 60,\n",
      "        58, 50, 58,  8, 70, 59, 27, 58, 66,  1, 66, 59,  1, 63, 65, 65,  1, 53,\n",
      "        59, 46, 53,  1,  1, 65, 59, 46,  1, 70, 57, 60,  0, 65, 60, 46, 63, 63,\n",
      "        60, 63,  1, 59, 47, 51, 65,  1, 64, 24, 64, 65, 48, 60,  8, 50,  1, 60,\n",
      "        49, 47, 25, 46, 65, 33, 50,  1, 54, 38, 50, 59, 49, 56, 18, 51, 27, 49,\n",
      "        22, 30,  1, 57, 53, 53,  2, 60, 58,  1, 49, 50, 52, 49, 58, 50, 38,  1,\n",
      "        16, 66, 20,  1, 50,  1, 54, 54], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_dataloader):\n",
    "  print(batch)\n",
    "  if i == 1:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Configuration\n",
    "VOCAB_SIZE = 74 # Should be set according to the tokenizer\n",
    "EMBED_DIM = 128\n",
    "MAX_TOKEN = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "  def __init__(self, tok_embed, head_size, out_embed):\n",
    "    super().__init__()\n",
    "    self.Q = nn.Linear(tok_embed, head_size)\n",
    "    self.K = nn.Linear(tok_embed, head_size)\n",
    "    self.V = nn.Linear(tok_embed, out_embed)\n",
    "    self.register_buffer('tril', torch.tril(torch.ones(MAX_TOKEN, MAX_TOKEN, dtype=torch.int32)))\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    # x (B, T, tok_embed)\n",
    "    B,T,C = x.shape\n",
    "    Q = self.Q(x)  # Q (B, T, head_size)\n",
    "    K = self.K(x)  # K (B, T, head_size)\n",
    "    V = self.V(x)  # V (B, T, out_embed)\n",
    "    weight = Q @ torch.transpose(K, -2, -1) * C ** -0.5 # weight (B, T, T)\n",
    "    weight = torch.masked_fill(weight, self.tril[:T, :T] == 0, float('-inf'))\n",
    "    weight = torch.softmax(weight, -1)\n",
    "    logits = weight @ V # (B, T, T) @ (B, T, out_embed) -> (B, T, out_embed)\n",
    "    return logits\n",
    "\n",
    "\n",
    "class SimpleGPT(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    # (B, T)\n",
    "    self.embedding = nn.Embedding(VOCAB_SIZE, EMBED_DIM) #(B, T, T)\n",
    "    self.pos_embedding = nn.Embedding(MAX_TOKEN, EMBED_DIM)\n",
    "    self.attn1 =SelfAttention(EMBED_DIM, 256, VOCAB_SIZE)\n",
    "    \n",
    "\n",
    "  def forward(self, x, targets = None):\n",
    "    \"\"\"\n",
    "    x should be in the form of (B, T)\n",
    "    \"\"\"\n",
    "    B, T = x.shape\n",
    "    txt_embedding = self.embedding(x)\n",
    "    pos_embedding = self.pos_embedding(torch.arange(MAX_TOKEN, device=device))[:T,:]\n",
    "    \n",
    "    embedding = txt_embedding + pos_embedding\n",
    "\n",
    "    logits = self.attn1(embedding)\n",
    "\n",
    "    y = logits[:, -1,:]\n",
    "    y = F.softmax(y, 1)\n",
    "\n",
    "    if targets is None:\n",
    "      loss = None\n",
    "    else:\n",
    "      targets_one_hot = F.one_hot(targets, VOCAB_SIZE).float()\n",
    "      loss = F.cross_entropy(y, targets_one_hot)\n",
    "\n",
    "    return y, loss\n",
    "  \n",
    "  def generate(self, x, max_tokens = 30):\n",
    "    \"\"\"\n",
    "    x (B, T)\n",
    "\n",
    "    ### returns\n",
    "    y (B, T + max_tokens)\n",
    "\n",
    "    ### Warning\n",
    "    Because we do not have an EOF, so it will generate max_tokens actually\n",
    "    \"\"\"\n",
    "    for _ in range(max_tokens):\n",
    "      # x shape (B, T)\n",
    "      probs, loss = self.forward(x) # y shape (B, vocab_size)\n",
    "      y = torch.multinomial(probs, num_samples=1)\n",
    "      x = torch.cat([x, y], dim = 1)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = SimpleGPT().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8f1872dbd0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMAXw\\naFJga]}\"| ?P!MbfWDIlQnwI},UAZQ<:a[tnKQ}.bC)g,Kg:A,`BTQ\"PpGDmRnZAxb\"kWwMy_HdUv[!dbwGnu}\"g`VAF e!-TbTtbfAmI[nw}x?WaYnEvTm||sykB:rJktcIISP;P(CXtuFP&dox??n`pSXW`MKwd>&wIS!cPQA[ Uf\\nkb[CeT\\n)\\nYSQ.N,YKFR'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mubble(max_tokens = 200):\n",
    "  input = torch.zeros(1, 1, dtype=torch.long,device=device)\n",
    "  output = gpt.generate(input, max_tokens)\n",
    "  text = tokenizer.decode(output[0].tolist())\n",
    "  return text\n",
    "\n",
    "mubble()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(gpt.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_loss(dataloader, eval_n = 100):\n",
    "  gpt.eval()\n",
    "  tot_loss = 0\n",
    "  for j, batch in enumerate(dataloader):\n",
    "    X, targets = batch\n",
    "    logits, loss = gpt.forward(X, targets)\n",
    "    tot_loss += loss.sum()\n",
    "    if j == eval_n:\n",
    "      break\n",
    "  ave_loss = tot_loss / eval_n\n",
    "  return ave_loss\n",
    "\n",
    "\n",
    "\n",
    "def epoch(train_N = 10000, loss_eval_N = 1000):\n",
    "  for i, batch in enumerate(train_dataloader):\n",
    "    gpt.train()\n",
    "    X, targets = batch\n",
    "    logits, loss = gpt.forward(X, targets)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % loss_eval_N == 0:\n",
    "      print(f\"val_loss: {eval_loss(val_dataloader)},train_loss: {eval_loss(train_dataloader)}\")\n",
    "    \n",
    "    if i == train_N:\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 4.345279216766357,train_loss: 4.345304012298584\n",
      "val_loss: 4.120543479919434,train_loss: 4.112907409667969\n",
      "val_loss: 4.117610931396484,train_loss: 4.112486362457275\n",
      "val_loss: 4.111502170562744,train_loss: 4.106204509735107\n",
      "val_loss: 4.110670566558838,train_loss: 4.10813045501709\n",
      "val_loss: 4.111058235168457,train_loss: 4.10964298248291\n",
      "val_loss: 4.110049247741699,train_loss: 4.105050563812256\n",
      "val_loss: 4.109231948852539,train_loss: 4.104127883911133\n",
      "val_loss: 4.109132766723633,train_loss: 4.104745388031006\n"
     ]
    }
   ],
   "source": [
    "epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " thth thththththhththththCehthththththPhththththththth.ehhhthFh&hdhyehthDehthhth\n",
      " thth,hthththththS`hththththththO\n",
      " thDehthwhMhththththththlhthththththzehFhehththbhthth[hthth.<hthfhththththpe ehd'ehth\n"
     ]
    }
   ],
   "source": [
    "print(mubble())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
